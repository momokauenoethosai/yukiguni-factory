import os
import csv
import json
import time
import requests
from datetime import datetime
import pytz
from typing import List, Dict, Tuple
from dotenv import load_dotenv
import google.generativeai as genai
import PIL.Image
from io import BytesIO

load_dotenv()

# Streamlit Secrets ã¾ãŸã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰APIã‚­ãƒ¼ã‚’å–å¾—
try:
    import streamlit as st
    GEMINI_API_KEY = st.secrets.get("GOOGLE_GEMINI_API_KEY") or os.getenv('GOOGLE_GEMINI_API_KEY')
except:
    GEMINI_API_KEY = os.getenv('GOOGLE_GEMINI_API_KEY')

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‹ã‚‰ã®å‹•çš„ãƒ‘ã‚¹è¨­å®š
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
INPUT_CSV_PATH = os.path.join(PROJECT_ROOT, 'output', 'chirashi_data_selenium.csv')
OUTPUT_CSV_PATH = os.path.join(PROJECT_ROOT, 'output', 'chirashi_data_with_products.csv')
IMAGE_CACHE_DIR = os.path.join(PROJECT_ROOT, 'cache', 'images')

os.makedirs(IMAGE_CACHE_DIR, exist_ok=True)

def download_image(url: str, base_filename: str, timestamp: str) -> str:
    """ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‘ã‚¹ã‚’è¿”ã™"""
    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ããƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ
    name_parts = base_filename.split('.')
    if len(name_parts) > 1:
        filename = f"{name_parts[0]}_{timestamp}.{name_parts[-1]}"
    else:
        filename = f"{base_filename}_{timestamp}.jpg"

    filepath = os.path.join(IMAGE_CACHE_DIR, filename)

    try:
        response = requests.get(url, timeout=30)
        response.raise_for_status()
        with open(filepath, 'wb') as f:
            f.write(response.content)
        print(f"Downloaded image: {filename}")
        return filepath
    except Exception as e:
        print(f"Error downloading image {url}: {e}")
        return None

def extract_flyer_metadata(image_path: str) -> dict:
    """ç”»åƒã‹ã‚‰ãƒãƒ©ã‚·ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚¿ã‚¤ãƒˆãƒ«ã€æœŸé–“ã€é£Ÿå“ãƒãƒ©ã‚·ã‹ã©ã†ã‹ï¼‰ã‚’æŠ½å‡º"""
    try:
        genai.configure(api_key=GEMINI_API_KEY)
        model = genai.GenerativeModel('gemini-2.5-flash')

        image = PIL.Image.open(image_path)

        prompt = """
        ã“ã®ãƒãƒ©ã‚·ç”»åƒã‹ã‚‰ä»¥ä¸‹ã®æƒ…å ±ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚JSONå½¢å¼ã§è¿”ã—ã¦ãã ã•ã„ï¼š

        {
          "is_food_flyer": "YES"ã¾ãŸã¯"NO"ï¼ˆä¸»ã«é£Ÿå“ãƒ»é£²æ–™ãƒ»é£Ÿæã‚’æ‰±ã£ã¦ã„ã‚‹ãƒãƒ©ã‚·ã‹ã©ã†ã‹ï¼‰,
          "flyer_title": "ãƒãƒ©ã‚·ã®ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆä¾‹ï¼šå¤œå¸‚ã€ãƒ‘ãƒ³deãƒŠã‚¤ãƒˆã€å¹´æœ«å¹´å§‹ã”ã¡ãã†ã”äºˆç´„æ‰¿ã‚Šï¼‰",
          "period": "æœŸé–“ï¼ˆä¾‹ï¼š11/10ï½11/16ã€11/1ï½11/30ï¼‰"
        }

        æ³¨æ„äº‹é …ï¼š
        - é£Ÿå“ãƒãƒ©ã‚·ã®åˆ¤å®šï¼šé‡èœã€è‚‰ã€é­šã€æœç‰©ã€æƒ£èœã€ãƒ‘ãƒ³ã€é£²æ–™ã€é£Ÿæãªã©ãŒä¸»ä½“ãªã‚‰"YES"ã€è¡£æ–™å“ãƒ»å®¶é›»ãƒ»é›‘è²¨ãªã©ãªã‚‰"NO"
        - ãƒãƒ©ã‚·ã‚¿ã‚¤ãƒˆãƒ«ï¼šç”»åƒä¸Šéƒ¨ã‚„ãƒ¡ã‚¤ãƒ³ã«è¡¨ç¤ºã•ã‚Œã¦ã„ã‚‹ã‚­ãƒ£ãƒƒãƒã‚³ãƒ”ãƒ¼ã‚„ã‚¤ãƒ™ãƒ³ãƒˆå
        - æœŸé–“ï¼šæœ‰åŠ¹æœŸé–“ã‚„é–‹å‚¬æœŸé–“ï¼ˆmm/ddï½mm/ddå½¢å¼ãŒç†æƒ³ï¼‰
        - æƒ…å ±ãŒèª­ã¿å–ã‚Œãªã„å ´åˆã¯ç©ºæ–‡å­—""ã‚’è¿”ã—ã¦ãã ã•ã„
        """

        response = model.generate_content([prompt, image])

        try:
            import json
            response_text = response.text.strip()
            response_text = response_text.replace('```json', '').replace('```', '').strip()
            metadata = json.loads(response_text)

            return {
                'is_food_flyer': metadata.get('is_food_flyer', '').upper() == 'YES',
                'flyer_title': metadata.get('flyer_title', ''),
                'period': metadata.get('period', '')
            }
        except json.JSONDecodeError as e:
            print(f"Error parsing JSON response: {e}")
            print(f"Response text: {response_text[:200]}...")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¾“æ¥ã®é£Ÿå“åˆ¤å®šã®ã¿
            is_food = "YES" in response.text.upper()
            return {'is_food_flyer': is_food, 'flyer_title': '', 'period': ''}

    except Exception as e:
        print(f"Error extracting flyer metadata: {e}")
        return {'is_food_flyer': False, 'flyer_title': '', 'period': ''}

def is_food_flyer(image_path: str) -> bool:
    """ç”»åƒãŒé£Ÿå“ãƒãƒ©ã‚·ã‹ã©ã†ã‹ã‚’åˆ¤å®šï¼ˆå¾Œæ–¹äº’æ›æ€§ã®ãŸã‚æ®‹ã™ï¼‰"""
    metadata = extract_flyer_metadata(image_path)
    return metadata['is_food_flyer']

def analyze_chirashi_with_gemini(image_path: str, super_name: str, shop_name: str) -> List[Dict]:
    """Gemini APIã‚’ä½¿ç”¨ã—ã¦ãƒãƒ©ã‚·ç”»åƒã‹ã‚‰å•†å“æƒ…å ±ã‚’æŠ½å‡º"""
    if not os.path.exists(image_path):
        print(f"Image not found: {image_path}")
        return []

    try:
        genai.configure(api_key=GEMINI_API_KEY)
        model = genai.GenerativeModel('gemini-2.5-flash')

        image = PIL.Image.open(image_path)

        prompt = f"""
        ã“ã®ã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒãƒ¼ã‚±ãƒƒãƒˆã®ãƒãƒ©ã‚·ç”»åƒã‹ã‚‰å•†å“æƒ…å ±ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚
        ã‚¹ãƒ¼ãƒ‘ãƒ¼å: {super_name}
        åº—èˆ—å: {shop_name}

        ä»¥ä¸‹ã®å½¢å¼ã§ã€ã™ã¹ã¦ã®å•†å“æƒ…å ±ã‚’JSONé…åˆ—ã¨ã—ã¦è¿”ã—ã¦ãã ã•ã„ï¼š
        [
          {{
            "product_name": "å•†å“åï¼ˆãƒ–ãƒ©ãƒ³ãƒ‰åã€å•†å“ã®è©³ç´°ãªåç§°ã€å®¹é‡ã€å€‹æ•°ãªã©ã‚‚å«ã‚ã¦ï¼‰",
            "price_without_tax": "ç¨æŠœä¾¡æ ¼ï¼ˆæ•°å€¤ã®ã¿ã€å††ã¯ä¸è¦ï¼‰",
            "price_with_tax": "ç¨è¾¼ä¾¡æ ¼ï¼ˆæ•°å€¤ã®ã¿ã€å††ã¯ä¸è¦ï¼‰",
            "discount": "å‰²å¼•æƒ…å ±ï¼ˆã‚ã‚Œã°ï¼‰",
            "category": "ã‚«ãƒ†ã‚´ãƒªãƒ¼ï¼ˆé‡èœã€è‚‰ã€é­šã€æƒ£èœã€é£²æ–™ãªã©ï¼‰"
          }}
        ]

        å•†å“åã®è¨˜è¼‰ä¾‹ï¼š
        - æ‚ªã„ä¾‹ï¼šã€Œã‚«ãƒ¬ãƒ¼ã€ã€Œç‰›ä¹³ã€ã€Œãƒ‘ãƒ³ã€
        - è‰¯ã„ä¾‹ï¼šã€Œãƒã‚¦ã‚¹ ãƒãƒ¼ãƒ¢ãƒ³ãƒˆã‚«ãƒ¬ãƒ¼ ç”˜å£ 230gã€ã€Œæ˜æ²»ãŠã„ã—ã„ç‰›ä¹³ 1000mlã€ã€Œãƒ¤ãƒã‚¶ã‚­ è¶…èŠ³é†‡ 6æšåˆ‡ã€

        æ³¨æ„äº‹é …ï¼š
        - å•†å“åã¯ç”»åƒã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ãƒ–ãƒ©ãƒ³ãƒ‰åã€è©³ç´°ãªå•†å“åã€å®¹é‡ã€å€‹æ•°ãªã©ã‚’ã™ã¹ã¦å«ã‚ã¦è¨˜è¼‰
        - ãƒ¡ãƒ¼ã‚«ãƒ¼åã‚„ãƒ–ãƒ©ãƒ³ãƒ‰åãŒèª­ã¿å–ã‚Œã‚‹å ´åˆã¯å¿…ãšå«ã‚ã‚‹
        - å®¹é‡ï¼ˆgã€mlã€å€‹ãªã©ï¼‰ãŒè¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹å ´åˆã¯å¿…ãšå«ã‚ã‚‹
        - ä¾¡æ ¼ãŒèª­ã¿å–ã‚Œãªã„å ´åˆã¯ "ä¸æ˜" ã¨è¨˜è¼‰
        - ç¨æŠœä¾¡æ ¼ãŒæ˜è¨˜ã•ã‚Œã¦ã„ãªã„å ´åˆã¯ã€ç¨è¾¼ä¾¡æ ¼ã‹ã‚‰è¨ˆç®—ï¼ˆç¨ç‡10%ã¨ã—ã¦ï¼‰
        - ã§ãã‚‹ã ã‘å¤šãã®å•†å“ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„
        """

        response = model.generate_content([prompt, image])

        response_text = response.text.strip()
        response_text = response_text.replace('```json', '').replace('```', '').strip()

        try:
            products = json.loads(response_text)
            return products if isinstance(products, list) else []
        except json.JSONDecodeError as e:
            print(f"Error parsing JSON response: {e}")
            print(f"Response text: {response_text[:500]}...")
            return []

    except Exception as e:
        print(f"Error analyzing image with Gemini: {e}")
        return []

def process_chirashi_data():
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€å„ãƒãƒ©ã‚·ç”»åƒã‚’åˆ†æã—ã¦çµæœã‚’ä¿å­˜"""
    with open(INPUT_CSV_PATH, 'r', encoding='utf-8') as infile:
        reader = csv.DictReader(infile)
        rows = list(reader)

    results = []

    # MAX_FLYERSã®è¨­å®š
    try:
        import streamlit as st
        max_flyers_setting = st.secrets.get("MAX_FLYERS") or os.getenv('MAX_FLYERS', str(len(rows)))
    except:
        max_flyers_setting = os.getenv('MAX_FLYERS', str(len(rows)))

    max_flyers = int(max_flyers_setting)
    rows_to_process = rows[:max_flyers]

    # æ—¥æœ¬æ™‚é–“ã§å®Ÿè¡Œæ™‚åˆ»ã‚’ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¨ã—ã¦ä½¿ç”¨
    jst = pytz.timezone('Asia/Tokyo')
    timestamp = datetime.now(jst).strftime("%Y%m%d_%H%M%S")

    # CSVãƒ•ã‚¡ã‚¤ãƒ«ã®åˆæœŸåŒ–ï¼ˆãƒ˜ãƒƒãƒ€ãƒ¼æ›¸ãè¾¼ã¿ï¼‰
    fieldnames = ['url', 'super_name', 'shop_name', 'chirashi_png_path', 'flyer_title', 'period', 'scraped_at',
                  'product_name', 'price_without_tax', 'price_with_tax', 'discount', 'category']

    # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆæœŸåŒ–
    with open(OUTPUT_CSV_PATH, 'w', encoding='utf-8', newline='') as outfile:
        writer = csv.DictWriter(outfile, fieldnames=fieldnames)
        writer.writeheader()

    for idx, row in enumerate(rows_to_process):
        # åœæ­¢ãƒ•ãƒ©ã‚°ã‚’ãƒã‚§ãƒƒã‚¯
        stop_flag_file = os.path.join(PROJECT_ROOT, "temp_stop_flag.txt")
        if os.path.exists(stop_flag_file):
            print("â¹ï¸ åœæ­¢è¦æ±‚ã‚’å—ä¿¡ã—ã¾ã—ãŸã€‚å‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã™ã€‚")
            break

        print(f"\nğŸ“‹ Processing {idx + 1}/{len(rows_to_process)}: {row['super_name']} - {row['shop_name']}")
        flyer_title = row.get('flyer_title', '')
        period = row.get('period', '')
        display_title = flyer_title if flyer_title else period
        print(f"ğŸ–¼ï¸ ãƒãƒ©ã‚·ã‚¿ã‚¤ãƒˆãƒ«: {display_title}")

        image_url = row['chirashi_png_path']
        base_image_filename = f"{row['super_name']}_{row['shop_name']}_{idx}.jpg"
        base_image_filename = base_image_filename.replace('/', '_').replace(' ', '_')

        print(f"ğŸ“¥ ç”»åƒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é–‹å§‹: {base_image_filename}")
        image_path = download_image(image_url, base_image_filename, timestamp)
        if not image_path:
            print(f"âŒ ç”»åƒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—")
            continue

        print(f"âœ… ç”»åƒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†: {base_image_filename}")

        # ãƒãƒ©ã‚·ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
        print(f"ğŸ” ãƒãƒ©ã‚·æƒ…å ±æŠ½å‡ºä¸­...")
        image_metadata = extract_flyer_metadata(image_path)

        if not image_metadata['is_food_flyer']:
            print(f"âŒ éé£Ÿå“ãƒãƒ©ã‚·ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—")
            continue

        print(f"âœ… é£Ÿå“ãƒãƒ©ã‚·ã¨åˆ¤å®š")

        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å¾—ã‚‰ã‚ŒãŸæƒ…å ±ã§ç©ºç™½ã‚’è£œå®Œ
        extracted_title = image_metadata.get('flyer_title', '')
        extracted_period = image_metadata.get('period', '')

        # å…ƒã®CSVãƒ‡ãƒ¼ã‚¿ã¨ç”»åƒã‹ã‚‰æŠ½å‡ºã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’ãƒãƒ¼ã‚¸
        final_flyer_title = flyer_title if flyer_title else extracted_title
        final_period = period if period else extracted_period

        print(f"ğŸ“‹ è£œå®Œå¾Œ - ã‚¿ã‚¤ãƒˆãƒ«: '{final_flyer_title}' æœŸé–“: '{final_period}'")
        print(f"ğŸ¤– AI OCRåˆ†æé–‹å§‹...")
        products = analyze_chirashi_with_gemini(image_path, row['super_name'], row['shop_name'])

        if products:
            print(f"âœ… AI OCRå®Œäº†: {len(products)}å€‹ã®å•†å“ã‚’æ¤œå‡º")
        else:
            print(f"âš ï¸ AI OCRå®Œäº†: å•†å“æ¤œå‡ºãªã—")

        # çµæœã‚’æº–å‚™
        rows_to_save = []
        if products:
            for product in products:
                result_row = {
                    'url': row['url'],
                    'super_name': row['super_name'],
                    'shop_name': row['shop_name'],
                    'chirashi_png_path': row['chirashi_png_path'],
                    'flyer_title': final_flyer_title,
                    'period': final_period,
                    'scraped_at': row['scraped_at'],
                    'product_name': product.get('product_name', ''),
                    'price_without_tax': product.get('price_without_tax', ''),
                    'price_with_tax': product.get('price_with_tax', ''),
                    'discount': product.get('discount', ''),
                    'category': product.get('category', '')
                }
                rows_to_save.append(result_row)
                results.append(result_row)
        else:
            result_row = {
                'url': row['url'],
                'super_name': row['super_name'],
                'shop_name': row['shop_name'],
                'chirashi_png_path': row['chirashi_png_path'],
                'flyer_title': final_flyer_title,
                'period': final_period,
                'scraped_at': row['scraped_at'],
                'product_name': 'å–å¾—å¤±æ•—',
                'price_without_tax': '',
                'price_with_tax': '',
                'discount': '',
                'category': ''
            }
            rows_to_save.append(result_row)
            results.append(result_row)

        # é€æ¬¡ä¿å­˜ï¼ˆè¿½è¨˜ï¼‰
        with open(OUTPUT_CSV_PATH, 'a', encoding='utf-8', newline='') as outfile:
            writer = csv.DictWriter(outfile, fieldnames=fieldnames)
            writer.writerows(rows_to_save)

        time.sleep(2)

    print(f"\nåˆ†æå®Œäº†ï¼çµæœã‚’ {OUTPUT_CSV_PATH} ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")
    print(f"åˆè¨ˆ {len(results)} ä»¶ã®å•†å“æƒ…å ±ã‚’æŠ½å‡ºã—ã¾ã—ãŸã€‚")

if __name__ == "__main__":
    if not GEMINI_API_KEY:
        print("ã‚¨ãƒ©ãƒ¼: GOOGLE_GEMINI_API_KEY ãŒ .env ãƒ•ã‚¡ã‚¤ãƒ«ã«è¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        print(".env ãƒ•ã‚¡ã‚¤ãƒ«ã«ä»¥ä¸‹ã®å½¢å¼ã§è¨­å®šã—ã¦ãã ã•ã„ï¼š")
        print("GOOGLE_GEMINI_API_KEY=your_actual_api_key")
    else:
        process_chirashi_data()